{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.4.0-cp313-cp313-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp313-cp313-win_amd64.whl.metadata (52 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp313-cp313-win_amd64.whl.metadata (116 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-12.0.0-cp313-cp313-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading numpy-2.4.0-cp313-cp313-win_amd64.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 5.5/12.3 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 31.2 MB/s  0:00:00\n",
      "Downloading pandas-2.3.3-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 7.3/11.0 MB 36.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 34.3 MB/s  0:00:00\n",
      "Downloading matplotlib-3.10.8-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 6.8/8.1 MB 35.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 31.8 MB/s  0:00:00\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 6.0/8.0 MB 29.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 27.0 MB/s  0:00:00\n",
      "Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp313-cp313-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 27.0 MB/s  0:00:00\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl (73 kB)\n",
      "Downloading pillow-12.0.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   -------------------------------------- - 6.8/7.0 MB 33.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 32.5 MB/s  0:00:00\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scipy-1.16.3-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 7.1/38.5 MB 35.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 14.4/38.5 MB 37.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 20.4/38.5 MB 32.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 27.8/38.5 MB 33.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.4/38.5 MB 34.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 33.1 MB/s  0:00:01\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, cycler, scipy, pandas, contourpy, scikit-learn, matplotlib, seaborn\n",
      "\n",
      "   ----------------------------------------  0/16 [pytz]\n",
      "   -- -------------------------------------  1/16 [tzdata]\n",
      "   ----- ----------------------------------  2/16 [threadpoolctl]\n",
      "   ------- --------------------------------  3/16 [pyparsing]\n",
      "   ------- --------------------------------  3/16 [pyparsing]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ---------- -----------------------------  4/16 [pillow]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   ------------ ---------------------------  5/16 [numpy]\n",
      "   --------------- ------------------------  6/16 [kiwisolver]\n",
      "   ----------------- ----------------------  7/16 [joblib]\n",
      "   ----------------- ----------------------  7/16 [joblib]\n",
      "   ----------------- ----------------------  7/16 [joblib]\n",
      "   ----------------- ----------------------  7/16 [joblib]\n",
      "   ----------------- ----------------------  7/16 [joblib]\n",
      "   ----------------- ----------------------  7/16 [joblib]\n",
      "   ----------------- ----------------------  7/16 [joblib]\n",
      "   ----------------- ----------------------  7/16 [joblib]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   -------------------- -------------------  8/16 [fonttools]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   ------------------------- -------------- 10/16 [scipy]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   --------------------------- ------------ 11/16 [pandas]\n",
      "   ------------------------------ --------- 12/16 [contourpy]\n",
      "   ------------------------------ --------- 12/16 [contourpy]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   -------------------------------- ------- 13/16 [scikit-learn]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ----------------------------------- ---- 14/16 [matplotlib]\n",
      "   ------------------------------------- -- 15/16 [seaborn]\n",
      "   ------------------------------------- -- 15/16 [seaborn]\n",
      "   ------------------------------------- -- 15/16 [seaborn]\n",
      "   ------------------------------------- -- 15/16 [seaborn]\n",
      "   ------------------------------------- -- 15/16 [seaborn]\n",
      "   ------------------------------------- -- 15/16 [seaborn]\n",
      "   ---------------------------------------- 16/16 [seaborn]\n",
      "\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 joblib-1.5.3 kiwisolver-1.4.9 matplotlib-3.10.8 numpy-2.4.0 pandas-2.3.3 pillow-12.0.0 pyparsing-3.3.1 pytz-2025.2 scikit-learn-1.8.0 scipy-1.16.3 seaborn-0.13.2 threadpoolctl-3.6.0 tzdata-2025.3\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.5-cp313-cp313-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.19 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from wordcloud) (2.4.0)\n",
      "Requirement already satisfied: pillow in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from wordcloud) (12.0.0)\n",
      "Requirement already satisfied: matplotlib in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from wordcloud) (3.10.8)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: joblib in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from nltk) (1.5.3)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.11.3-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from matplotlib->wordcloud) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from matplotlib->wordcloud) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from matplotlib->wordcloud) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from matplotlib->wordcloud) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from matplotlib->wordcloud) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
      "Downloading wordcloud-1.9.5-cp313-cp313-win_amd64.whl (307 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 30.3 MB/s  0:00:00\n",
      "Downloading regex-2025.11.3-cp313-cp313-win_amd64.whl (277 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, click, nltk, wordcloud\n",
      "\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   -------- ------------------------------- 1/5 [regex]\n",
      "   ---------------- ----------------------- 2/5 [click]\n",
      "   ---------------- ----------------------- 2/5 [click]\n",
      "   ---------------- ----------------------- 2/5 [click]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [wordcloud]\n",
      "   -------------------------------- ------- 4/5 [wordcloud]\n",
      "   ---------------------------------------- 5/5 [wordcloud]\n",
      "\n",
      "Successfully installed click-8.3.1 nltk-3.9.2 regex-2025.11.3 tqdm-4.67.1 wordcloud-1.9.5\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from xgboost) (2.4.0)\n",
      "Requirement already satisfied: scipy in e:\\ml-pipeline-mlops\\.venv\\lib\\site-packages (from xgboost) (1.16.3)\n",
      "Downloading xgboost-3.1.2-py3-none-win_amd64.whl (72.0 MB)\n",
      "   ---------------------------------------- 0.0/72.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 3.4/72.0 MB 30.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 8.7/72.0 MB 26.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 16.0/72.0 MB 29.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 23.1/72.0 MB 30.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 29.9/72.0 MB 30.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 36.4/72.0 MB 31.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 43.8/72.0 MB 31.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 51.4/72.0 MB 32.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 58.5/72.0 MB 32.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 65.8/72.0 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.8/72.0 MB 32.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 72.0/72.0 MB 31.5 MB/s  0:00:02\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas matplotlib seaborn scikit-learn\n",
    "!pip install wordcloud nltk\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement yaml (from versions: none)\n",
      "ERROR: No matching distribution found for yaml\n"
     ]
    }
   ],
   "source": [
    "!pip install yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Personal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Personal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np        # For numerical operations\n",
    "import pandas as pd       # For data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing WordCloud for text visualization\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Importing NLTK for natural language processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords    # For stopwords\n",
    "\n",
    "\n",
    "# Downloading NLTK data\n",
    "nltk.download('stopwords')   # Downloading stopwords data\n",
    "nltk.download('punkt')       # Downloading tokenizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('spam.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns name\n",
    "df.rename(columns = {'v1': 'target', 'v2': 'text'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['target'] = encoder.fit_transform(df['target'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove Duplicate\n",
    "df = df.drop_duplicates(keep = 'first')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Porter Stemmer for text stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Importing the string module for handling special characters\n",
    "import string\n",
    "\n",
    "# Creating an instance of the Porter Stemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase transformation and text preprocessing function\n",
    "def transform_text(text):\n",
    "    # Transform the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization using NLTK\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Removing special characters\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "            \n",
    "    # Removing stop words and punctuation\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    # Loop through the tokens and remove stopwords and punctuation\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "        \n",
    "    # Stemming using Porter Stemmer\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    # Join the processed tokens back into a single string\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazi avail bugi n great world la e buffet cine got amor wat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_text('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4               nah think goe usf live around though  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "tfid = TfidfVectorizer(max_features = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfid.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel= \"sigmoid\", gamma  = 1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "lrc = LogisticRegression(solver = 'liblinear', penalty = 'l1')\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = 2 )\n",
    "abc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\n",
    "bc = BaggingClassifier(n_estimators = 50, random_state = 2)\n",
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \n",
    "xgb  = XGBClassifier(n_estimators = 50, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC': svc,\n",
    "    'KNN': knc,\n",
    "    'NB': mnb,\n",
    "    'DT': dtc,\n",
    "    'LR': lrc,\n",
    "    'RF': rfc,\n",
    "    'Adaboost': abc,\n",
    "    'Bgc': bc,\n",
    "    'ETC': etc,\n",
    "    'GBDT': gbdt,\n",
    "    'xgb': xgb\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "def train_classifier(clfs, X_train, y_train, X_test, y_test):\n",
    "    clfs.fit(X_train,y_train)\n",
    "    y_pred = clfs.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    return accuracy , precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.9661508704061895\n",
      "Precision:  0.9327731092436975\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.9274661508704062\n",
      "Precision:  1.0\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.9709864603481625\n",
      "Precision:  0.9655172413793104\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.9381044487427466\n",
      "Precision:  0.9021739130434783\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.9632495164410058\n",
      "Precision:  0.9629629629629629\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.971953578336557\n",
      "Precision:  0.943089430894309\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.9613152804642167\n",
      "Precision:  0.9375\n",
      "\n",
      "For:  Bgc\n",
      "Accuracy:  0.965183752417795\n",
      "Precision:  0.9180327868852459\n",
      "\n",
      "For:  ETC\n",
      "Accuracy:  0.9729206963249516\n",
      "Precision:  0.9296875\n",
      "\n",
      "For:  GBDT\n",
      "Accuracy:  0.9506769825918762\n",
      "Precision:  0.9393939393939394\n",
      "\n",
      "For:  xgb\n",
      "Accuracy:  0.9709864603481625\n",
      "Precision:  0.9576271186440678\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "for name , clfs in clfs.items():\n",
    "    current_accuracy, current_precision = train_classifier(clfs, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
